import os
import soundfile as sf
from typing import List, Tuple, Dict, Any
from silero_vad import load_silero_vad, read_audio, get_speech_timestamps


def silero_vad_segmentation(audio_path: str, vad_params: Dict[str, Any] = None) -> Tuple[List[Dict], Any, int]:
    """
    ä½¿ç”¨Silero VADè¿›è¡Œè¯­éŸ³æ´»åŠ¨æ£€æµ‹å’ŒéŸ³é¢‘åˆ†æ®µ

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        vad_params: VADå‚æ•°å­—å…¸

    Returns:
        Tuple of (speech_timestamps, audio_data, sample_rate)
    """
    if vad_params is None:
        vad_params = {'min_speech_duration_ms': 500, 'min_silence_duration_ms': 500}

    print("ğŸµ åŠ è½½Silero VADæ¨¡å‹...")
    model = load_silero_vad()

    print("ğŸ“ è¯»å–éŸ³é¢‘æ–‡ä»¶...")
    wav = read_audio(audio_path)

    print("ğŸ” å¼€å§‹VADè¯­éŸ³æ£€æµ‹...")
    speech_timestamps = get_speech_timestamps(
        wav,
        model,
        **vad_params,
        return_seconds=True,
    )

    print(f"âœ… Silero VADæ£€æµ‹å®Œæˆï¼Œæ‰¾åˆ° {len(speech_timestamps)} ä¸ªè¯­éŸ³æ®µ")

    # ä½¿ç”¨soundfileè¯»å–éŸ³é¢‘ç”¨äºåç»­å¤„ç†
    audio_data, sample_rate = sf.read(audio_path)

    return speech_timestamps, audio_data, sample_rate


def export_silero_segments(
    segments: List[Dict],
    original_audio: Any,
    sample_rate: int,
    output_dir: str = "silero_segments",
    min_duration: float = 0.5,
    max_duration: float = 60.0,
) -> List[Dict]:
    """
    å¯¼å‡ºSilero VADæ£€æµ‹åˆ°çš„è¯­éŸ³æ®µ

    Args:
        segments: è¯­éŸ³æ®µåˆ—è¡¨
        original_audio: åŸå§‹éŸ³é¢‘æ•°æ®
        sample_rate: é‡‡æ ·ç‡
        output_dir: è¾“å‡ºç›®å½•
        min_duration: æœ€å°æ®µæ—¶é•¿
        max_duration: æœ€å¤§æ®µæ—¶é•¿

    Returns:
        å¯¼å‡ºçš„è¯­éŸ³æ®µä¿¡æ¯åˆ—è¡¨
    """
    os.makedirs(output_dir, exist_ok=True)

    exported_segments = []

    for i, segment in enumerate(segments):
        start_time = segment['start']
        end_time = segment['end']
        duration = segment['end'] - segment['start']

        # è¿‡æ»¤å¤ªçŸ­æˆ–å¤ªé•¿çš„æ®µ
        if duration < min_duration or duration > max_duration:
            continue

        # è½¬æ¢ä¸ºæ ·æœ¬ç‚¹
        start_sample = int(start_time * sample_rate)
        end_sample = int(end_time * sample_rate)

        # ç¡®ä¿ä¸è¶…å‡ºéŸ³é¢‘èŒƒå›´
        start_sample = max(0, min(start_sample, len(original_audio)))
        end_sample = max(0, min(end_sample, len(original_audio)))

        if end_sample > start_sample:
            # æå–éŸ³é¢‘æ®µ
            segment_audio = original_audio[start_sample:end_sample]
            output_path = os.path.join(output_dir, f"silero_segment_{i+1:04d}.wav")

            # ä½¿ç”¨soundfileä¿å­˜éŸ³é¢‘
            sf.write(output_path, segment_audio, sample_rate)

            exported_segments.append(
                {
                    'index': i + 1,
                    'file_path': output_path,
                    'start_time': start_time,
                    'end_time': end_time,
                    'duration': duration,
                }
            )

            print(f"ğŸ’¾ å¯¼å‡ºæ®µ {i+1:04d}: {start_time:.2f}s - {end_time:.2f}s " f"(æ—¶é•¿: {duration:.2f}s)")

    return exported_segments


def time_string_to_seconds(time_str: str) -> float:
    """
    å°†æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºç§’æ•°

    Args:
        time_str: æ—¶é—´å­—ç¬¦ä¸² (HH:MM:SS,mmm æˆ– HH:MM:SS.mmm)

    Returns:
        ç§’æ•°
    """
    time_str = time_str.replace(',', '.')
    parts = time_str.split(':')

    if len(parts) == 3:
        hours = int(parts[0])
        minutes = int(parts[1])
        seconds = float(parts[2])
        return hours * 3600 + minutes * 60 + seconds
    else:
        return float(time_str)


def format_timestamp_srt(seconds: float) -> str:
    """
    å°†ç§’æ•°æ ¼å¼åŒ–ä¸ºSRTæ—¶é—´æˆ³æ ¼å¼ (HH:MM:SS,mmm)

    Args:
        seconds: ç§’æ•°

    Returns:
        SRTæ—¶é—´æˆ³å­—ç¬¦ä¸²
    """
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds - int(seconds)) * 1000)

    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def generate_srt_content(subtitles: List[Dict]) -> str:
    """
    ç”ŸæˆSRTæ–‡ä»¶å†…å®¹

    Args:
        subtitles: å­—å¹•åˆ—è¡¨

    Returns:
        SRTæ–‡ä»¶å†…å®¹å­—ç¬¦ä¸²
    """
    srt_content = ""

    for i, subtitle in enumerate(subtitles, 1):
        srt_content += f"{i}\n"
        srt_content += f"{subtitle['start']} --> {subtitle['end']}\n"
        srt_content += f"{subtitle['text']}\n\n"

    return srt_content


def parse_transcription_segments(
    transcription_lines: List[str], segment_start_time: float, segment_end_time: float
) -> List[Dict]:
    """
    è§£æè½¬å½•ç»“æœï¼Œä½¿ç”¨VADåˆ†æ®µçš„æ—¶é—´æˆ³

    Args:
        transcription_lines: è½¬å½•ç»“æœè¡Œåˆ—è¡¨
        segment_start_time: åˆ†æ®µå¼€å§‹æ—¶é—´
        segment_end_time: åˆ†æ®µç»“æŸæ—¶é—´

    Returns:
        è°ƒæ•´åçš„å­—å¹•æ®µåˆ—è¡¨
    """
    adjusted_segments = []

    # æ£€æŸ¥è½¬å½•ç»“æœæ˜¯å¦ä¸ºç©º
    if not transcription_lines:
        return adjusted_segments

    # åˆå¹¶æ‰€æœ‰æ–‡æœ¬è¡Œ
    full_text = ' '.join(transcription_lines).strip()

    if full_text:
        adjusted_segments.append(
            {
                'start': format_timestamp_srt(segment_start_time),
                'end': format_timestamp_srt(segment_end_time),
                'text': full_text,
            }
        )

    return adjusted_segments
